{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4028d2",
   "metadata": {},
   "source": [
    "# 02_Split Wav Duration\n",
    "#### Code to split audio wav files to 10s duration for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "852e534f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import plotly.express as px\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings('ignore', message='Trying to estimate tuning from empty frequency set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af699b7",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Iteratively go through files\n",
    "def walk_through_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8924d285",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting files into wav: 20it [06:25, 19.28s/it]\n"
     ]
    }
   ],
   "source": [
    "#Splitting the WAVS\n",
    "\n",
    "in_dir = fr'N:\\Mark\\Audio Diss\\OCC_SVM_Data\\yavari_2018\\audios_part_2\\GY3\\Data\\wav_to_split'\n",
    "out_dir = fr'N:\\Mark\\Audio Diss\\OCC_SVM_Data\\yavari_2018\\audios_part_2\\GY3\\Data\\wav_split'\n",
    "\n",
    "segment_duration = 10 #segment duration in seconds based on extracted gunshot duration\n",
    "for fname in tqdm(walk_through_files(in_dir), desc='splitting files into wav'):\n",
    "    audio, sample_rate = librosa.load(fname)\n",
    "    duration = len(audio) / float(sample_rate)\n",
    "    \n",
    "    split = []\n",
    "    segment_length = sample_rate * segment_duration\n",
    "    num_sections = int(np.ceil(len(audio)/segment_length))\n",
    "    \n",
    "    for i in range(num_sections): #splitting the file\n",
    "        t = audio[i * segment_length: (i+1) * segment_length]\n",
    "        split.append(t)\n",
    "        \n",
    "    for i in range(num_sections): #saving the file\n",
    "        strip_filetype = os.path.basename(fname[:-4])\n",
    "        output = f'{strip_filetype}_{str(i)}.wav'\n",
    "        sf.write(os.path.join(out_dir, output), split[i], sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a55e8c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Processing Audio into dataframe - getting audio features\n",
    "def process_audio_file_splits(fname):\n",
    "    #stripping filetypes and dir from filename and split it to parts\n",
    "    filename = os.path.basename(fname[:-4]) #strip dir\n",
    "    f_parts = filename.split('_') #split at underscore\n",
    "    rec_info, year_date, file_id, segment = f_parts\n",
    "    \n",
    "    #_Separating f_parts further\n",
    "    #Only works for files following 'S4A03839_20180813_054429_99' convention\n",
    "    r_type = rec_info[:2]\n",
    "    r_name = rec_info[2:]\n",
    "    year = year_date[:4]\n",
    "    date = year_date[4:]\n",
    "    \n",
    "    #_loading audio for processing\n",
    "    audio, sample_rate = librosa.load(fname)\n",
    "    duration = len(audio)/float(sample_rate)\n",
    "    \n",
    "    #_creating Spectrograms and MFCC\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=128)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate)\n",
    "    \n",
    "    #_Creating Self-similarity matrix\n",
    "    hop_length = 1024\n",
    "    chroma = librosa.feature.melspectrogram(y=audio,sr=sample_rate, hop_length=hop_length)\n",
    "    chroma_stack = librosa.feature.stack_memory(chroma, n_steps=10, delay=3)\n",
    "    R = librosa.segment.recurrence_matrix(chroma_stack)\n",
    "    R_aff = librosa.segment.recurrence_matrix(chroma_stack, metric='cosine', mode='affinity')\n",
    "    ssm = R_aff\n",
    "    \n",
    "    #_Create shape (Modify if needed)\n",
    "    desired_shape = (128,128)\n",
    "    \n",
    "    #_Normalise Spectrogram, MFCC, SSM for image creation\n",
    "    log_mel_spectrogram_norm = (log_mel_spectrogram - np.min(log_mel_spectrogram)/(np.max(log_mel_spectrogram) - np.min(log_mel_spectrogram))) #log-min/max-min\n",
    "    mfcc_norm = (mfcc - np.min(mfcc)) / (np.max(mfcc) - np.min(mfcc))\n",
    "    ssm_norm = (ssm - np.min(ssm)) / (np.max(ssm) - np.min(ssm))\n",
    "    \n",
    "    #_Resize to desired_shape\n",
    "    lms_r = zoom(log_mel_spectrogram_norm,\n",
    "                (desired_shape[0] / log_mel_spectrogram_norm.shape[0],\n",
    "                desired_shape[1] / log_mel_spectrogram_norm.shape[1]))\n",
    "    mfcc_r = zoom(mfcc_norm,\n",
    "                 (desired_shape[0] / mfcc_norm.shape[0],\n",
    "                 desired_shape[1] / mfcc_norm.shape[1]))\n",
    "    ssm_r = zoom(ssm_norm,\n",
    "                (desired_shape[0] / ssm_norm.shape[0],\n",
    "                desired_shape[1] / ssm_norm.shape[1]))\n",
    "    \n",
    "    #_Get the values\n",
    "    return {\n",
    "        'file_name': filename,\n",
    "        'file_id': file_id,\n",
    "        'r_type': r_type,\n",
    "        'r_name': r_name,\n",
    "        'date': date,\n",
    "        'year': year,\n",
    "        'signal': audio,\n",
    "        'sample_rate': sample_rate,\n",
    "        'duration': duration,\n",
    "        'mel_spectrogram': mel_spectrogram,\n",
    "        'log_mel_spectrogram': log_mel_spectrogram,\n",
    "        'mfcc': mfcc,\n",
    "        'ssm': ssm,\n",
    "        'shape': desired_shape,\n",
    "        'lms_r': lms_r,#for image gen\n",
    "        'mfcc_r': mfcc_r, #for image gen\n",
    "        'ssm_r': ssm_r #for image gen\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3366e7",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pickling: 7200it [36:41,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files were processed\n",
      "CPU times: total: 44min 18s\n",
      "Wall time: 36min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "directory = fr'N:\\Mark\\Audio Diss\\OCC_SVM_Data\\yavari_2018\\audios_part_2\\GY3\\Data\\wav_split'\n",
    "pickle_dir = fr'N:\\Mark\\Audio Diss\\pickle_data'\n",
    "pickle_file_path = os.path.join(pickle_dir, 'split_processed_audio.pickle')\n",
    "batch_size = 10\n",
    "\n",
    "is_processing_skipped = False\n",
    "is_processing_complete = False\n",
    "\n",
    "if os.path.exists(pickle_file_path):\n",
    "    existing_data = pd.read_pickle(pickle_file_path)\n",
    "    if np.logical_xor(len(existing_data), len(list(walk_through_files(directory)))):\n",
    "        is_processing_skipped = True\n",
    "        split_audio_data = pd.read_pickle(pickle_file_path)\n",
    "        print('split_audio_data loaded')\n",
    "        \n",
    "if not is_processing_skipped:\n",
    "    processed_data = []\n",
    "    batch_counter = 0\n",
    "        \n",
    "\n",
    "    for fname in tqdm(walk_through_files(directory), desc='pickling'):\n",
    "        try:\n",
    "            processed_data.append(process_audio_file_splits(fname)) #Processes the files\n",
    "            batch_counter += 1 #up the counter by 1\n",
    "            \n",
    "            #_Saves intermediate results and clear memory after processing a batch\n",
    "            if batch_counter >= batch_size:\n",
    "                split_audio_data = pd.DataFrame(processed_data)\n",
    "                split_audio_data.to_pickle(pickle_file_path, protocol=pickle.HIGHEST_PROTOCOL) #_Appends dataframe to pickle file\n",
    "                processed_data.clear()\n",
    "                batch_counter = 0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error processing file {fname}: {e}')\n",
    "\n",
    "            \n",
    "    if len(list(walk_through_files(directory))) == 0 and batch_counter == 0:\n",
    "        is_processing_complete = True\n",
    "\n",
    "    if is_processing_complete and len(processed_data) > 0:\n",
    "        split_audio_data = pd.DataFrame(processed_data)\n",
    "        split_audio_data.to_pickle(pickle_file_path, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    elif not is_processing_complete:\n",
    "        print('No files were processed') #Pickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0bed8a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pickling: 7200it [58:12,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 10min 44s\n",
      "Wall time: 1h 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time #loading pickle file as split_audio_data\n",
    "pickle_dir = fr'N:\\Mark\\Audio Diss\\pickle_data'\n",
    "pickle_file_path = os.path.join(pickle_dir, 'split_processed_audio.pickle')\n",
    "\n",
    "if os.path.exists(pickle_file_path):\n",
    "        split_audio_data = pd.read_pickle(pickle_file_path)\n",
    "        print('split_audio_data loaded')\n",
    "else:\n",
    "    for fname in tqdm(walk_through_files(directory), desc='pickling'):\n",
    "        if fname.endswith('.wav'):\n",
    "            processed_data.append(process_audio_file_splits(fname))\n",
    "    split_audio_data = pd.DataFrame(processed_data)\n",
    "    split_audio_data.to_pickle(pickle_file_path, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "457efdf4",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n"
     ]
    }
   ],
   "source": [
    "#Checking length of data\n",
    "print(len(split_audio_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
